---
title: "30 Day Chart Challenge"
author: "Simon"
date: "06/04/2021"
output: html_document
---

```{r setup, include=FALSE}
myPaths <- .libPaths()
myPaths <- c(myPaths, "D:/Libraries")
myPaths <- c(myPaths, "D:\\Libraries\\win-library\\4.0")
.libPaths(myPaths)  # add new path
library(readODS)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rvest) 
library(magrittr)
library(waffle)
library(readxl)
library(streamgraph)
library(ggstream)
library(data.table)
library(ggforce)
library(cowplot)
library(gridExtra)
library(ggplot2)
library(viridis)
#install.packages("palmerpenguins")
library(palmerpenguins)
library(ggridges)
library(tidyverse)
library(magick) 
library(scales)
#library(imager) 
library(cowplot)
library(waffle)
#library(patchwork)
library(showtext)
library(treemapify)
library(ggtext)
#install.packages(c("devtools", "mapproj", "tidyverse", "gtools"), lib="D:\\Libraries\\win-library\\4.0")
#devtools::install_github("marcusvolz/strava"
#library(strava)


font_add_google("Montserrat", "Montserrat")
font_add_google("Sacramento", "Sacramento")
font_add_google("Catamaran", "Catamaran")
showtext_auto()
```

## 30 Day Chart Challenge 

This R Markdown document will contain a visualisation for each day within the #30daychartchallenge. 
https://twitter.com/30DayChartChall

![All 30 days themes](D:\\30daychartchallenge\\themes.jpg) 

# Day 1- Part to Whole

Using Openly available data from the National Travel Survey on Car Availability by Household

![NTS Data](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/905929/nts0203.ods)
```{r Day 1} 
# Read in the Data
NTS<- read_ods("D:\\30daychartchallenge\\30daychart\\data\\day1data_2.ods", sheet=1, skip=10,col_names=TRUE)

## Data Cleaning ##
# Remove NA Rows 
NTS <- NTS[!is.na(NTS$Purpose) & !is.na(NTS$`No car / van`) & !is.na(NTS$`One car / van`) & !is.na(NTS$`Two or more cars / vans`),]
# Remove extra columns 
NTS <- NTS[,1:4]
# Remove unwanted rows 
NTS <- NTS[1:18,]

# Set data as numeric 
NTS[,2:4] <- sapply(NTS[,2:4],as.numeric)

# Convert data to wide format to enable ggplot 
NTS_wide <- NTS %>% gather(`Car Availability`, Percentage, `No car / van`:`Two or more cars / vans`, -Purpose)
# Set column names 
colnames(NTS_wide) <- c("Year", "Car Availability", "Percentage")
## Data Visualisation ## 
ggplot(data=NTS_wide, aes(x=Year, y=Percentage, group=`Car Availability`, fill=`Car Availability`)) + 
  geom_bar(position="stack", stat="identity") + theme(axis.text.x=element_text(angle=90)) + labs(title="National Travel Survey- Car Availability by Household") + ylab("% Availability") + xlab("Year of Response") + geom_text(aes(label=round(Percentage,1)), size=2.5, color="dark grey", position = position_stack(vjust=0.5)) + scale_fill_viridis_d()

# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day1.jpg", dpi = 300)
```


# Day 2- Pictogram

Using Openly available data from Wikipedia on Finalists in the UEFA Champions League

![Champions League Winners](https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals)
```{r Day 2, fig.height=40, fig.width=25}
# Read in the Data
Champions_table <- read_html("https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals") %>% 
    # list all tables on the page
    html_nodes(css = "table") %>%
    # select the one containing needed key words
    extract2(., str_which(string = . , pattern = "Seasons won")) %>% 
    # convert to a table
    html_table(fill = T)

# Keep Club Name, Title(s) and Runners-Up
Champions_table <- Champions_table[,1:3]

## Data Visualisation ## 
Champions_table$ID <- (1:nrow(Champions_table))

# Create list to store plots to 
p <- list()
# Loop through top 10 winners
for(i in 1:10){
  p[[i]] <- waffle(c("Champions"= Champions_table$`Title(s)`[i],"Runners-Up"= Champions_table$`Runners-up`[i]), rows=2, glyph_size = 4, title=paste0(Champions_table$Club[i]), colors = c("#FFD700", "#C0C0C0", NA))
}

do.call(grid.arrange,p)


# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day2.jpg",width=35, height=40, dpi = 300)
```


# Day 3- Historical

Using Openly available data from Human Development Reports by the UN on Gender Development Index

![HDI Index](http://hdr.undp.org/en/composite/trends)
```{r Day 3} 
# Read in the Data
url <- 'http://hdr.undp.org/sites/default/files/2020_statistical_annex_table_2.xlsx'
GPI <- rio::import(file = url,which = 1, skip=5) %>% 
  glimpse()

## Data Cleaning ## 
# Retain columns of use
GPI <- GPI[,c(1,2,3,5,7,9,11,13,15,17)]
# Rename columns 
colnames(GPI) <- c("HDI Rank", "Country", "1990","2000", "2010", "2014", "2015", "2017", "2018", "2019")
# Remove anything without a HDI Rank 
GPI <- GPI[!is.na(GPI$`HDI Rank`),]

# Convert data to wide format to enable ggplot 
GPI_wide <- GPI %>% gather(`Year`, Percentage, `1990`:`2019`, -Country)

GPI_wide$Percentage <- as.numeric(GPI_wide$Percentage)
## Data Visualisation ## 

GPI_wide2 <- GPI_wide[GPI_wide$`HDI Rank`>=180,]
GPI_wide2$Year<-as.numeric(GPI_wide2$Year)

GPI_wide24 <- GPI_wide2 %>% 
  group_by(Year, Country) %>% 
  summarise(n=sum(Percentage)) %>% 
  mutate(percentage_2 = n/sum(n))

ggplot(data=GPI_wide2, aes(x=Year,y=Percentage, color=Country)) + xlab("Year") + ylab("HDI") + labs(title="Human Development Index in worst 9 countries since 2010") + scale_color_viridis_d() + geom_line(alpha=0.6 , size=1) + geom_point() + theme_minimal() + theme(plot.background = element_rect(fill="black"), panel.grid =element_line(color="grey"), axis.line = element_line(colour = "grey"), text=element_text(color="white"))

# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day3.jpg", dpi = 300)
```

# Day 4- Magical

Using Openly available data from Google Search Trends Worldwide in past 12 months for Witches and Wizards

![Google Search Trends](https://trends.google.com/trends/explore?q=wizard)
```{r Day 4} 
# Read in the Data
data_1<- fread("D:\\30daychartchallenge\\30daychart\\data\\day4data-1.csv")
data_2<- fread("D:\\30daychartchallenge\\30daychart\\data\\day4data-2.csv")

# Join datasets together
magic_data <- merge(data_1, data_2, by="Week")
colnames(magic_data) <- c("Week", "Witches", "Wizards")
# Convert data to wide format to enable ggplot 
magic_wide <- magic_data %>% gather(`Trend`, Popularity, `Witches`:`Wizards`, -Week)

# Normalise so equal search popularity means 0 
magic_wide$norm <- magic_data$Witches-magic_data$Wizards
# Remove duplicates data
magic_wide <- magic_wide[!duplicated(magic_wide$norm), ]

## Data Visualisation ## 

ggplot(data=magic_wide, aes(x=Week, y=norm)) + geom_line(size=0.9) + theme_dark() + theme(plot.background = element_rect("black")) + theme(panel.background = element_rect("black")) + theme(axis.text = element_text(color="white")) + geom_ribbon(data=,aes(x=Week,ymax=norm),ymin=0,alpha=0.3) +
theme(legend.position="none") + theme(panel.grid = element_blank()) + labs(title="Difference in Google Search Popularity between Witches and Wizards. \n Positive value means Witches were more popular that week") + ylab("Google Search Trend Popularity") + xlab("Week") + theme(title=element_text(color="white"), text=element_text(family="serif")) + geom_link2(lwd=1.5,
             aes(color = after_stat(y < 0)))+
  scale_color_manual(
    values = c("yellow", "blue")) 

library(extrafont)
loadfonts(device = "win")
# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day4.jpg", dpi = 300)
```
# Day 5- Slope

Using Openly available data from the National Travel Survey for 17-20 Year Olds on reasons why they do not complete driving license examination. 

![NTS Data](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/905929/nts0203.ods)
```{r Day 5, fig.height=10, fig.width=10}
# Read in the Data
NTS<- read_ods("D:\\30daychartchallenge\\30daychart\\data\\day1data.ods", sheet=2, skip=8,col_names=TRUE)

## Data Cleaning ##
# Find which row begins and ends the data we need (using 17-20 data)
row_begin <- which(NTS$Reasons=="Reasons for not learning to drive by age: England, 17-20")
row_end <- which(NTS$Reasons=="Driving without a licence")

# Find which 'Unweighted sample size:' is closest to row_begin
row_end <- row_end - row_begin
row_end <- min(row_end[row_end > 0])
row_end <- row_end + row_begin
# Subset to 17-20 data
NTS <- NTS[row_begin: row_end,]
# Remove top 5 rows of info data 
NTS <- NTS[5:20,]

# Set data as numeric 
NTS[,2:12] <- sapply(NTS[,2:12],as.numeric)

# Convert data to wide format to enable ggplot 
NTS_wide <- NTS %>% gather(Time, Percentage, `2009`:`2019`, -Reasons)

## Data Analysis ## 
# Visualise data to understand it and add linear regression line
ggplot(data=NTS_wide, aes(x=Time, y=Percentage, group=Reasons, color=Reasons)) + 
  geom_smooth(method="lm", linetype="dashed", se=T, color="black") + 
  geom_line(stat="identity", size=0.9) + theme_classic()  + facet_wrap(~Reasons, labeller=label_wrap_gen()) + theme(legend.position="none") + theme(axis.text.x=element_text(angle=90)) + labs(title="National Travel Survey- Reasons Not to Complete Driving Licence") + ylab("% of 17-20 Year Olds") + xlab("Year of Response") + scale_color_viridis_d()


# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day5.jpg", dpi = 300)
```
# Day 6- Experimental

Using Openly available data from Wikipedia on 2017 Per Capita CO2 Emissions

![Emissions Data](https://en.wikipedia.org/wiki/List_of_countries_by_carbon_dioxide_emissions#Per_capita_CO2_emissions)

```{r Day6, fig.height=15, fig.width=15}

# Read in the Data
Emissions_table <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_carbon_dioxide_emissions#Per_capita_CO2_emissions") %>% 
    # list all tables on the page
    html_nodes(css = "table") %>%
    # select the one containing needed key words
    extract2(., str_which(string = . , pattern = "Afghanistan")) %>% 
    # convert to a table
    html_table(fill = T)

# Remove top 4 rows 
Emissions_table <- Emissions_table[5:nrow(Emissions_table),]

# Keep column 1 and 8 (per capita)
Emissions_table <- Emissions_table[, c(1,8)]
#Set column names
colnames(Emissions_table) <-c("Country", "val")
# Set to numeric
Emissions_table$val<-as.numeric(Emissions_table$val)

# Sort by value of Per Capita Emissions
Emissions_table <- Emissions_table[order(Emissions_table$val),]

# Add Continent
continent <- fread("D:\\30daychartchallenge\\30daychart\\data\\day6continent.csv")
continent <- continent[,c(1,6)]

# Data Cleaning on Country Name to match them 

# Join together 
Emissions_table <- merge(Emissions_table, continent, by.x="Country", by.y="country", all.x=FALSE)
Emissions_table$continent <- as.factor(Emissions_table$continent)


# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 4
to_add <- data.frame( matrix(NA, empty_bar*nlevels(Emissions_table$continent), ncol(Emissions_table)) )
colnames(to_add) <- colnames(Emissions_table)
to_add$continent <- rep(levels(Emissions_table$continent), each=empty_bar)
Emissions_table <- rbind(Emissions_table, to_add)
Emissions_table <- Emissions_table %>% arrange(continent, val)
Emissions_table$id <- seq(1, nrow(Emissions_table))

# ----- This section prepare a dataframe for labels ---- #
# Get the name and the y position of each label
label_data <- Emissions_table
 
# calculate the ANGLE of the labels
number_of_bar <- nrow(label_data)
angle <-  90 - 360 * (label_data$id-0.5) /number_of_bar     # I subtract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
 
# calculate the alignment of labels: right or left
# If I am on the left part of the plot, my labels have currently an angle < -90
label_data$hjust<-ifelse( angle < -90, 1, 0)
 
# flip angle BY to make them readable
label_data$angle<-ifelse(angle < -90, angle+180, angle)

# Create Label 
label_data$label <- paste0(label_data$Country, " ", label_data$val)
# ----- ------------------------------------------- ---- #

# prepare a data frame for base lines
base_data <- Emissions_table %>% 
  group_by(continent) %>% 
  summarize(start=min(id), end=max(id) - empty_bar) %>% 
  rowwise() %>% 
  mutate(title=mean(c(start, end)))


# Make the plot
p <- ggplot(Emissions_table, aes(x=as.factor(id), y=val, fill=continent)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity", alpha=0.5) +
  ylim(-100,120) +
  theme_minimal() + 
  labs(title="2017 Per Capita CO2 Emissions by Country") +
  theme(
    legend.position = "none",
    text=element_text(color="white"),
    axis.text = element_blank(),
    #axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.background = element_rect(fill="black"),
    plot.title=element_text(size=12, hjust=0.2, face='bold', color="white"),
    plot.margin = unit(rep(-1,4), "cm") 
  ) +
  coord_polar()  + 
  # Add the labels, using the label_data dataframe that we have created before
  geom_text(data=label_data, aes(x=id, y=val+10, label=label, hjust=hjust), color="white", fontface="italic",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE, position=position_jitter(width=0.1,height=0.1))  + # Add base line information
geom_segment(data=base_data, aes(x = start, y = -5, xend = end, yend = -5), colour = "white", alpha=0.8, size=0.6 , inherit.aes = FALSE )  +
geom_text(data=base_data, aes(x = title, y = -18, label=continent), hjust=c(1,1,0,0,0), colour = "white", alpha=0.8, size=4, fontface="bold", inherit.aes = FALSE)
 
 
p

# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day6.jpg", dpi = 300)
```



# Day 7- Physical

Using Personal Strava Data

![Strava]()

```{r Day7, fig.height=15, fig.width=15}

# Read in the Data
data <- process_data("D:\\30daychartchallenge\\30daychart\\data\\activities\\")

#' Plot ridges of Strava activities by weekdays
#'
#' @param data A data frame output from process_data()
#'
#' @return A plot displaying ridges
#' @export
plot_ridges <- function(data) {
  # Function for processing an activity on a minute-by-minute basis; active = 1, not active = 0
  compute_day_curve <- function(df_row) {
    start <- as.numeric(activity_time[df_row, "start_time"])
    end <- as.numeric(activity_time[df_row, "end_time"])
    wday <- as.character(activity_time[df_row, "wday"])

    result <- data.frame(time = seq(as.POSIXct("00:00:00", format = "%H:%M:%S"),
                                    as.POSIXct("23:59:58", format = "%H:%M:%S"),
                                    by = 60
    )) %>%
      mutate(
        time_end = lead(time, default = as.POSIXct("23:59:59", format = "%H:%M:%S")),
        active = ifelse(time > start & time_end < end, 1, 0), wday = wday
      )

    result
  }

  activity_time <- data %>%
    group_by(id) %>%
    summarise(start = min(time), end = max(time)) %>%
    mutate(
      start_time = as.POSIXct(strftime(start, format = "%H:%M:%S"), format = "%H:%M:%S"),
      end_time = as.POSIXct(strftime(end, format = "%H:%M:%S"), format = "%H:%M:%S"),
      duration = end_time - start_time,
      wday = lubridate::wday(start, week_start = 1)
    )

  # Process all activities
  plot_data <- 1:nrow(activity_time) %>%
    purrr::map_df(~ compute_day_curve(.x), .id = "id") %>%
    filter(!is.na(active), active > 0) %>%
    mutate(wday = as.factor(wday))

  plot_data$wday <- factor(plot_data$wday, levels = rev(levels(plot_data$wday)))

  # Create plot
  p <- ggplot() +
    ggridges::geom_density_ridges(aes(x = time, y = wday, fill=wday), plot_data, size = 0.5) +
    ggridges::theme_ridges() +
    scale_y_discrete(expand = c(0.01, 0), labels = c("Sun", "Sat", "Fri", "Thu", "Wed", "Tue", "Mon")) +
    scale_x_datetime(expand = c(0, 0), date_labels = "%I:%M %p") +
    theme(plot.background=element_rect(fill="black"), panel.grid = element_blank(), plot.margin = unit(rep(1, 4), "cm"), axis.text = element_text(color="white", size=25), axis.line = element_line(color="white"), plot.title = element_text(color="white", size=25), panel.grid.major.y = element_line(color="white")) +
    xlab(NULL) +
    ylab(NULL) + theme(legend.position="none") + labs(title="Time of Strava Activities") + scale_fill_viridis(discrete=TRUE)

  p
}

plot_ridges(data)

# save plot 
ggsave("D:\\30daychartchallenge\\30daychart\\day7.jpg", width=12, height=10, dpi = 300)
```



# Day 8- Animal

Using CITES data on 2017-2021 Zoo Trade, and country centroid data. 

![CITES](https://trade.cites.org/#) ![Country Centroids](https://developers.google.com/public-data/docs/canonical/countries_csv)

```{r Day8, fig.height=15, fig.width=15}

# Read in the Data
zoo_trade <- fread("D:\\30daychartchallenge\\30daychart\\data\\zoo_trade.csv")

# Keep only data with live being moved 
zoo_trade <- zoo_trade[zoo_trade$Term=="live",]

# Calculate number of moved specimens 
zoo_trade$num_moved <- ifelse(is.na(zoo_trade$`Importer reported quantity`),zoo_trade$`Exporter reported quantity`, zoo_trade$`Importer reported quantity`)

# Read in country centroid dataset 
country_centroid <- fread("D:\\30daychartchallenge\\30daychart\\data\\country_centroid.csv")

# Join country centroids to the data for both importer and exporter 
zoo_trade <- merge(zoo_trade, country_centroid, by.x="Importer", by.y="country")
zoo_trade <- merge(zoo_trade, country_centroid, by.x="Exporter", by.y="country")

# Remove extra columns and rename columns 
zoo_trade <- subset(zoo_trade, select=c("Year", "Exporter", "Importer", "latitude.x", "longitude.x", "latitude.y", "longitude.y", "num_moved"))
colnames(zoo_trade) <- c("Year", "Importer", "Exporter", "Im_lat", "Im_long", "Ex_lat", "Ex_long", "num_moved")


# Group data by Country and Year 
zoo_trade2 <- zoo_trade %>% group_by(Importer, Year) %>% summarise("total"=sum(num_moved)) %>% ungroup()

# Plot barchart
# Remove data with MY as too large to display
zoo_trade2 <- zoo_trade2[zoo_trade2$Importer!="MY",]

# Calculate yearly average 
av <- zoo_trade2 %>% group_by(Year) %>% summarise("av"=mean(total)) %>% ungroup()


# Join average on 
zoo_trade3 <- merge(zoo_trade2, av, by.x="Year", by.y="Year")

ggplot(zoo_trade3, aes(x=Importer, y=total,fill=as.factor(Year))) + 
         geom_bar(stat="identity", position="stack", color="black", alpha=0.8) + theme_classic() + labs(title="Movement of Trade for Zoos by CITES dataset, 2017-2021", fill="Year of Trade") + theme(legend.position="bottom", panel.background = element_rect(fill="#E0E0E0"))
       
       
# save plot, 
ggsave("D:\\30daychartchallenge\\30daychart\\day8.jpg", width=12, height=10, dpi = 300)

```

# Day 9- Distribution

Using Palmer Penguins Dataset {palmerpenguins}

![Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/)

```{r Day9, fig.height=15, fig.width=15}

# Read in the Data
penguins <- penguins

# Plot 1- distribution of Bill Depth 
p1<- ggplot(penguins, aes(x=bill_depth_mm, y=species, fill=species)) + ggridges::geom_density_ridges(alpha=0.9) + labs(title="Distribution of Bill Depth (mm)", caption=" Source: {palmerpenguins} | Artwork by @allison_horst") + xlab("Bill Depth (mm)" ) + theme(legend.position="none", axis.text.y = element_blank(), axis.title.y=element_blank(), plot.caption  = element_text(face="italic"), panel.background = element_rect(fill="#E5E5E3", colour="#E5E5E3"), panel.grid.major.x  = element_blank(), panel.grid.minor.x=element_blank()) + scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = FALSE) + theme(text=element_text(family="mono"))

# Plot 2- distribution of Bill Length
p2<- ggplot(penguins, aes(x=bill_length_mm, y=species, fill=species)) + ggridges::geom_density_ridges(alpha=0.9) + labs(title="Distribution of Bill Length (mm)", caption=" Source: {palmerpenguins} | Artwork by @allison_horst") + xlab("Bill Length (mm)" ) + theme(legend.position="none", axis.text.y = element_blank(), axis.title.y=element_blank(), plot.caption  = element_text(face="italic"), panel.background = element_rect(fill="#E5E5E3", colour="#E5E5E3"), panel.grid.major.x  = element_blank(), panel.grid.minor.x=element_blank()) + scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = FALSE) + theme(text=element_text(family="mono"))

# Plot correlation between the two 
p3<- ggplot(penguins, aes(x=bill_length_mm, y=bill_depth_mm, fill=species,color=species)) + geom_point(alpha=0.6) + geom_smooth(alpha=0.2) + labs(title="Bill Depth vs Bill Length (mm)", caption=" Source: {palmerpenguins} | Artwork by @allison_horst") + xlab("Bill Length (mm)" ) + ylab("Bill Depth (mm)") + theme(legend.position="none", plot.caption  = element_text(face="italic"), panel.background = element_rect(fill="#E5E5E3", colour="#E5E5E3"), panel.grid.major  = element_blank(), panel.grid.minor=element_blank()) + scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = FALSE) + scale_color_manual(values=c("darkorange","purple","cyan4"),
                    guide = FALSE) + theme(text=element_text(family="mono"))


# Read in pictures of Penguins and Visuals 
img1 <- magick::image_read("E:\\30daychartchallenge\\30daychart\\data\\lter_penguins.png")
img2 <- magick::image_read("E:\\30daychartchallenge\\30daychart\\data\\culmen_depth.png")

# Don't know how to get it to display image as a plot_grid output
#plot(img)

# Plot all together 
plot_grid(p1, p2, p3)

# save plot
ggsave("E:\\30daychartchallenge\\30daychart\\day9.jpg", width=12, height=10, dpi = 300)

```

# Day 10- Abstract 
![Blog about image colours](https://www.r-bloggers.com/2019/01/extracting-colours-from-your-images-with-image-quantization/)
```{r, Day 10}
im <- image_read("C:\\Users\\simon\\Downloads\\Day10.jpg")


## Reduce the colour used in image with image_quantize.  For example, let's say I want to reduce to 24 colours.
im %>%
  image_resize("500") %>%
  image_quantize(max=24)

## Function to get n number of colours out of your image.
get_colorPal <- function(im, n=15, cs="RGB"){
  # resize image to 100px 
  tmp <-im %>% image_resize("100") %>% 
    # set max colours to 8, and colorspace to RGB
    image_quantize(max=n, colorspace=cs) %>%  ## reducing colours! different colorspace gives you different result
    # convert to use as.data.frame
    magick2cimg() %>%  ## I'm converting, becauase I want to use as.data.frame function in imager package.
    # sort by colour hue 
    RGBtoHSV() %>% ## i like sorting colour by hue rather than RGB (red green blue)
    # made dataframe wide by colour
    as.data.frame(wide="c") %>%  #3 making it wide makes it easier to output hex colour
    # rescale colours
    mutate(hex=hsv(rescale(c.1, from=c(0,360)),c.2,c.3),
           hue = c.1,
           sat = c.2,
           value = c.3) %>%
    count(hex, hue, sat,value, sort=T) %>% 
    mutate(colorspace = cs)
  
  return(tmp %>% select(colorspace,hex,hue,sat,value,n)) ## I want data frame as a result.
  
}

# Return 50 of the colours in the image
colors <- get_colorPal(im, n=50)

#  Plot the colours found (https://github.com/linda-bennett/30-day-chart-challenge/blob/main/Distributions/Day%2010%20-%20Abstract/day10-abstract.R)
plot <-colors %>%  
  group_by(colorspace) %>%
  mutate(ypos=row_number(hue)) %>%  ## alter stacking order
  ggplot(aes(x=ypos, y=colorspace, fill=hex)) +
  #annotate("text", aes(x=colorspace, y=ypos, label=hex)) +
  geom_tile() +
  scale_fill_identity() +
  scale_x_continuous(breaks=NULL) +
  theme_void() +
  expand_limits(y=-1) 

# Show image 
plot_image <- ggplot() +
  draw_image("C:\\Users\\simon\\Downloads\\Day10.jpg") +
  theme_void()

# Display plots with the image 
p <- plot_image / plot +
  plot_annotation(
    title = "Colours from Sunset Image", caption= "30daychartchallenge-Day 10 |",
    theme = theme(plot.title = element_text(size = 40,
                                            hjust=0.5,
                                            vjust = 0,
                                            family="Montserrat"),
                  plot.caption=element_text(size=20, family="Montserrat", hjust=0.5),
                  plot.background = element_rect(fill = "#E5E5E3", colour = 'black', size = 3)) 
  )

# Output Image 
ggsave("E:\\30daychartchallenge\\30daychart\\day10.png", p, dpi=300)
```


# Day 11- Circular 

![Dplyr dataset](https://www.rpubs.com/gabrielbsousa/storms#:~:text=The%20%E2%80%9Cstorms%E2%80%9D%20dataset%20from%20the,the%20lifetime%20of%20a%20storm.)
```{r, Day 11}
# Day 11- Hurricanes
storms <- dplyr::storms

# Remove any records without hu_diameter
storms <- storms[!is.na(storms$hu_diameter),]

# Group by name and keep only the maximum hu_diameter 
storms<- storms %>% group_by(name) %>% mutate("max"= max(hu_diameter)) %>% ungroup()

# Keep only one record for each storm 
storms <- storms[!duplicated(storms$name),]

# Remove records with max of 0 
storms <- storms[storms$max!=0,]

# Add column to label only top 10 hurricanes 
storms$label_max <- NA
storms$label_max <- ifelse(storms$max>150,storms$name,NA)
# Proportional symbol plot over space
p<- ggplot(storms, aes(x=long, y=lat, size=max, color=status)) + geom_point(alpha=0.6)  +  scale_color_viridis_d()  + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="Montserrat", face="italic", size=20), plot.title=element_text(family="Montserrat", size=30), axis.text=element_text(family="Monserrat", size=30), axis.title=element_text(size=20),legend.position="none") + 
  labs(title="Hurricane Location", caption="#30daychartchallenge | Source: dplyr::storms") + xlab("Longitude")  + ylab("Latitude") +  scale_size_continuous(range = c(2, 12), breaks=pretty_breaks(7)) +
  geom_text(aes(label=label_max),hjust=0.5, vjust=-0.5, size=6, color="white", alpha=0.3)

p

# Distribution plot
p1<- ggplot(storms, aes(x=max, y=status, fill=status)) + ggridges::geom_density_ridges() + scale_fill_viridis_d() + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major = element_blank(), panel.grid.minor=element_blank(), axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y = element_blank(), plot.caption = element_text(family="Montserrat", face="italic", size=20), plot.title=element_text(family="Montserrat", size=30), axis.text=element_text(family="Monserrat", size=30), axis.title=element_text(size=20), legend.text=element_text(size=20), legend.position="bottom") + 
  labs(title="Distribution of Maximum Diameter of Area Experiencing Hurricane Winds (64 knots+) from Hurricanes", caption="#30daychartchallenge | Source: dplyr::storms", fill="") + xlab("Maximum Diameter of Area")

p1

# Plot together 
plot_grid(p, p1, align="h")

ggsave("E:\\30daychartchallenge\\30daychart\\day11.png", width=20, height=10, dpi=300)
```


# Day 12- Strips 
![Dplyr dataset](https://www.rpubs.com/gabrielbsousa/storms#:~:text=The%20%E2%80%9Cstorms%E2%80%9D%20dataset%20from%20the,the%20lifetime%20of%20a%20storm.)
```{r, Day 12}
# Day 12- Hurricanes
storms <- dplyr::storms

# Group by name and keep only the maximum hu_diameter 
storms<- storms %>% group_by(name) %>% mutate("max"= max(hu_diameter)) %>% ungroup()

# Keep only one record for each storm 
storms <- storms[!duplicated(storms$name),]

# Add counting column 
storms$count <- 1
# Group data by year and count number of storms in that year 
storms <- storms %>% group_by(year) %>% mutate("count"=sum(count), "mean_wind"=mean(wind)) %>% ungroup()

# Remove duplicated year records 
storms <- storms[!duplicated(storms$year), ]

# Proportional symbol plot over space
p<- ggplot(storms, aes(x=year, y=1, fill=mean_wind)) + geom_tile()  + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="Montserrat", face="italic", size=20), plot.title=element_text(family="Montserrat", size=30), axis.text=element_text(family="Monserrat", size=30), axis.title=element_text(size=20),legend.position="left", axis.ticks.y = element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank()) + 
  labs(title="Hurricane Mean Wind Speed by Year", caption="#30daychartchallenge | Source: dplyr::storms", fill="Wind Speeds (knots)") + xlab("Year")  +  scale_fill_viridis_c(direction=-1) +
  geom_text(aes(label=count),hjust=0.5, vjust=-0.5, size=6, angle=0, color="white", alpha=0.8)

p

ggsave("D:\\30daychartchallenge\\30daychart\\day12.png", width=10, height=5, dpi=300)
```


# Day 13- Correlations 

Using data from World Happiness Report and Sunlight Hours from UN

![Happiness Report](https://worldhappiness.report/ed/2021/#appendices-and-data)
![UN Sunlight](http://data.un.org/Data.aspx?q=Korea&d=CLINO&f=ElementCode%3A15%3BCountryCode%3AKO)

```{r, Day 12}

# Read in the data 
WHR <- read_xls("D:\\30daychartchallenge\\30daychart\\data\\Happiness.xls")
Sunlight <- fread("D:\\30daychartchallenge\\30daychart\\data\\Sunlight.csv")

# Subset data 
WHR <- subset(WHR, select=c("Country name", "Regional indicator", "Ladder score"))
# Add column of uppercase country name (to try and match to other data) 
WHR$Country_Name <- toupper(WHR$`Country name`)
Sunlight <- subset(Sunlight, select=c("Country or Territory", "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))

# Set -9999.99 to 0
Sunlight[,2:13][Sunlight[,2:13]==-9999.9] <- 0
# Add annual column  
Sunlight <- Sunlight %>% group_by(`Country or Territory`) %>% mutate("Annual_Sunlight_Hours"=Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov+Dec) %>% ungroup()

# Keep only records that don't contain a 0 
Sunlight <- Sunlight[(Sunlight$Jan!=0 & Sunlight$Feb!=0 & Sunlight$Mar!=0 & Sunlight$Apr!=0 & Sunlight$May!=0 & Sunlight$Jun!=0 & Sunlight$Jul!=0 & Sunlight$Aug!=0 & Sunlight$Sep!=0 & Sunlight$Oct!=0 & Sunlight$Nov!=0 & Sunlight$Dec!=0),]

# Mean data by Country
Sunlight <- Sunlight %>% group_by(`Country or Territory`) %>% summarise("Mean_Sunlight"=mean(Annual_Sunlight_Hours)) %>% ungroup()

# Join data to Happiness Report 
Joined <- merge(WHR, Sunlight, by.x="Country_Name", by.y="Country or Territory")


# Visualise 
p <- ggplot(Joined, aes(x=`Ladder score`, y=Mean_Sunlight, color=`Regional indicator`)) + geom_point(alpha=0.8) + geom_smooth(color="black", alpha=0.7) + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="Montserrat", face="italic", size=20), plot.title=element_text(family="Montserrat", size=30), axis.text=element_text(family="Monserrat", size=30), axis.title=element_text(size=20),legend.position="left", legend.title=element_text(family="Montserrat", size=20), legend.text = element_text(family="Montserrat", size=20)) + 
  labs(title="World Happiness Report vs Mean Sunlight Hours", color="Region") + ylab("Mean Annual Sunlight (Hours)") + xlab("World Happiness (ladder score)")  +  scale_color_viridis_d(direction=1, begin=0, end=0.9) 

p

ggsave("D:\\30daychartchallenge\\30daychart\\day13.png", width=10, height=5, dpi=300)
```


# Day 14- Space 

Using data on Space 
[Planetary Data](https://mdn.github.io/learning-area/html/tables/assessment-finished/planets-data.html)

```{r, Day 14}
# Read in the Data
Planets <- read_html("https://nssdc.gsfc.nasa.gov/planetary/factsheet/") %>% 
    # list all tables on the page
    html_nodes(css = "table") %>%
    # select the one containing needed key words
    extract2(., str_which(string = . , pattern = "MERCURY")) %>% 
    # convert to a table
    html_table(fill = T)

# Swap data around 
Planets <- as.data.table(t(Planets))
Planets <- Planets[,1:21]
# Set row 1 to column names 
names(Planets) <- Planets %>% slice(1) %>% unlist()
names(Planets)[names(Planets)==""]<- "Planet_Name"

# Remove extra data 
Planets <- Planets[2:11,]

# Remove moon 
Planets <- Planets[Planets$Planet_Name!="MOON",]

# Sort out diameter column 
Planets$`Diameter (km)`<-  as.numeric(gsub(",", "", gsub("\\.", "", Planets$`Diameter (km)`)))
Planets$`Mean Temperature (C)` <- as.numeric(Planets$`Mean Temperature (C)`)
# Set to numeric 
Planets <- as.data.frame(Planets)

# Set data as numeric 
Planets[,2:18] <- sapply(Planets[,2:18],as.numeric)

Planets$Planet_Name <- factor(Planets$Planet_Name, levels=c("MERCURY", "VENUS", "EARTH", "MARS", "JUPITER", "SATURN", "URANUS", "NEPTUNE", "PLUTO"))
# Visualise 
p <- ggplot(Planets, aes(x=`Mean Temperature (C)`, y=`Diameter (km)`, color=Planet_Name)) + geom_point(data=Planets, alpha=0.8, aes(size=`Mass (1024kg)`)) + 
  geom_line(data=Planets, aes(`Mean Temperature (C)`, y=`Diameter (km)`), color="black", linetype="dashed", alpha=0.3) +
theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="sans", face="italic", size=20), plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30), axis.title=element_text(size=20),legend.position="left", legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20)) + 
  labs(title="Mean Temperature (C) vs Planetary Diameter (km)", color="Planet") + ylab("Diameter (km)") + xlab("Mean Temperature (C)")  +  scale_color_viridis_d(direction=1, begin=0, end=0.9) +  scale_size_continuous(range = c(2, 12), breaks=pretty_breaks(7)) + annotate("text", x=max(Planets$`Mean Temperature (C)`-15), y=1000, label="Closest to the Sun", size=10)

p

ggsave("D:\\30daychartchallenge\\30daychart\\day14.png", width=10, height=7, dpi=300)

```


# Day 15- Multivariate 

Using Dplyr::Storms
[Planetary Data](https://mdn.github.io/learning-area/html/tables/assessment-finished/planets-data.html)

```{r, Day 15}
storms <- dplyr::storms

# Subset storms to keep numeric variables 
storms_sub <- storms[,c(2,3,4,5,6,7,10,11,12,13)]
# Remove any records containing NA 
storms_sub <- storms_sub[!is.na(storms_sub$ts_diameter) | !is.na(storms_sub$hu_diameter),]
# Compute correlation 
storms_cor <- round(cor(storms_sub),2)

# Keep lower half of the correlation matrix 
 # Get lower triangle of the correlation matrix
  get_lower_tri <- function(storms_cor){
    storms_cor[upper.tri(storms_cor)]<- NA
    return(storms_cor)
  }

storms_correlation_half <- get_lower_tri(storms_cor)


# Melt data 
storms_cor_melt <- melt(storms_correlation_half)
# Set column names 
colnames(storms_cor_melt) <- c("Variable_1", "Variable_2", "Correlation")


# Visualise correlation 
p <- ggplot(storms_cor_melt, aes(x=Variable_1, y=Variable_2, fill=Correlation)) + 
  geom_tile() + geom_text(aes(x=Variable_1, y=Variable_2, label=Correlation), color="black", size=7) + labs(title="Correlation Matrix of dplyr::storms variables") + theme(axis.title=element_blank()) + scale_fill_gradientn(colors=c("red", "yellow", "blue"), values=c(-0.5,0,1)) + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="black", color="black"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="sans", face="italic", size=20), plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30),legend.position="bottom", legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20))
p 



ggsave("D:\\30daychartchallenge\\30daychart\\day15.png", width=10, height=7, dpi=300)

```


# Day 16- Trees

Using globalforestwatch tree cover gain and CO2 emissions
[Global Forest Watch](https://www.globalforestwatch.org/dashboards/global/?category=summary&dashboardPrompts=eyJzaG93UHJvbXB0cyI6dHJ1ZSwicHJvbXB0c1ZpZXdlZCI6WyJ3aWRnZXRTZXR0aW5ncyIsImRvd25sb2FkRGFzaGJvYXJkU3RhdHMiXSwic2V0dGluZ3MiOnsic2hvd1Byb21wdHMiOnRydWUsInByb21wdHNWaWV3ZWQiOlsid2lkZ2V0U2V0dGluZ3MiXSwic2V0dGluZ3MiOnsic2hvd1Byb21wdHMiOnRydWUsInByb21wdHNWaWV3ZWQiOltdLCJzZXR0aW5ncyI6eyJvcGVuIjpmYWxzZSwic3RlcEluZGV4IjowLCJzdGVwc0tleSI6IiJ9LCJvcGVuIjp0cnVlLCJzdGVwSW5kZXgiOjAsInN0ZXBzS2V5Ijoid2lkZ2V0U2V0dGluZ3MifSwib3BlbiI6dHJ1ZSwic3RlcEluZGV4IjowLCJzdGVwc0tleSI6ImRvd25sb2FkRGFzaGJvYXJkU3RhdHMifSwib3BlbiI6dHJ1ZSwic3RlcHNLZXkiOiJzaGFyZVdpZGdldCJ9&location=WyJnbG9iYWwiXQ%3D%3D&map=eyJkYXRhc2V0cyI6W3sib3BhY2l0eSI6MC43LCJ2aXNpYmlsaXR5Ijp0cnVlLCJkYXRhc2V0IjoicHJpbWFyeS1mb3Jlc3RzIiwibGF5ZXJzIjpbInByaW1hcnktZm9yZXN0cy0yMDAxIl19LHsiZGF0YXNldCI6InBvbGl0aWNhbC1ib3VuZGFyaWVzIiwibGF5ZXJzIjpbImRpc3B1dGVkLXBvbGl0aWNhbC1ib3VuZGFyaWVzIiwicG9saXRpY2FsLWJvdW5kYXJpZXMiXSwiYm91bmRhcnkiOnRydWUsIm9wYWNpdHkiOjEsInZpc2liaWxpdHkiOnRydWV9LHsiZGF0YXNldCI6InRyZWUtY292ZXItbG9zcyIsImxheWVycyI6WyJ0cmVlLWNvdmVyLWxvc3MiXSwib3BhY2l0eSI6MSwidmlzaWJpbGl0eSI6dHJ1ZSwicGFyYW1zIjp7InRocmVzaG9sZCI6MzAsInZpc2liaWxpdHkiOnRydWV9fV19&treeCoverGain=eyJwYWdlIjoxNH0%3D) 
![C02 emissions](https://data.worldbank.org/indicator/EN.ATM.CO2E.PP.GD.KD?end=2012&most_recent_year_desc=true&start=2011)


```{r, Day 16}

# Read in the data 
tree_gain <- fread("D:\\30daychartchallenge\\30daychart\\data\\treecover_gain.csv")
co2 <- fread("D:\\30daychartchallenge\\30daychart\\data\\global_co2.csv")

# Set row 1 to column headers 
# Set row 1 to column names 
names(co2) <- co2 %>% slice(1) %>% unlist()
co2 <- co2[2:265,]

# subset columns 
co2 <- co2[, c(1,2,3,57,56,55,54,53,52, 51, 50, 49, 48, 47,46,45)]

# melt to get all emissions data in one column 
co2 <- melt(co2, id.vars=c("Country Name", "Country Code", "Indicator Name"), measure.vars = c("2012","2011","2010","2009","2008", "2007", "2006", "2005", "2004", "2003", "2002", "2001", "2000"))

# Calculate average emissions in co2 for 2002-2012 as single variable to match 2002-2012 tree gain 
co2<- co2 %>% group_by(`Country Code`) %>% summarise("Mean_Emissions"=mean(value, na.rm=TRUE))

# Join two datasets together using ISO Code (not all join due to matching issues- lack of time to solve!)
co2_tree <- merge(co2, tree_gain, by.x="Country Code", by.y="iso")

colnames(co2_tree) <- c("Country_Code", "Mean_Emissions_2000_2012", "Tree_cover_extent_2000", "Tree_gain_2000_2012")

# Remove any countries without either emissions or tree gain 
co2_tree <- co2_tree[(!is.na(co2_tree$Mean_Emissions_2000_2012) & !is.na(co2_tree$Tree_gain_2000_2012)),]


# Normalise tree gain by dividing by country size in ha
country_size <- read_html("https://www.worldometers.info/geography/largest-countries-in-the-world/") %>% 
    # list all tables on the page
    html_nodes(css = "table") %>%
    # select the one containing needed key words
    extract2(., str_which(string = . , pattern = "Russia")) %>% 
    # convert to a table
    html_table(fill = T)

country_size<- country_size[,c(2,5)]

# gsub to remove commas 
country_size$`Land Area (Km²)` <- gsub(",", "", country_size$`Land Area (Km²)`)
country_size$`Land Area (Km²)` <- as.numeric(country_size$`Land Area (Km²)`)

# Join on 3 letter Country code 
country_code <- read_html("https://www.iban.com/country-codes") %>% 
    # list all tables on the page
    html_nodes(css = "table") %>%
    # select the one containing needed key words
    extract2(., str_which(string = . , pattern = "Russia")) %>% 
    # convert to a table
    html_table(fill = T)
country_code <- country_code[,c(1,3)]

# Join size to 3 letter code
country_size <- merge(country_size, country_code, by="Country")

# Join this to the co2_tree data to normalise tree gain by land area 
co2_tree <- merge(co2_tree, country_size, by.x="Country_Code", by.y="Alpha-3 code")

# Convert km2 to ha 
co2_tree$Land_ha <- co2_tree$`Land Area (Km²)` * 100

# Divide tree gain by total land area to calculate % 
co2_tree$perc_gain <- co2_tree$Tree_gain_2000_2012 / co2_tree$Land_ha * 100
# Remove any countries without perc_gain 
co2_tree <- co2_tree[!is.na(co2_tree$perc_gain) & !is.na(co2_tree$Mean_Emissions_2000_2012),]


max(co2_tree$perc_gain)
# Visualise 
p <- ggplot(co2_tree, aes(area=perc_gain, fill=Mean_Emissions_2000_2012)) + geom_treemap() + scale_fill_viridis(direction=-1, option="D") + labs(title="Treemap of Tree Gain as % of Total Land Area and Emissions (kg per 2017 PPP $ of GDP) (2000-2012)", fill="Mean Emissions (kg per 2017 PPP $ of GDP) (2000-2012)") + geom_treemap_text(fontface = "italic", colour = "black", place = "centre", grow = TRUE, label=co2_tree$Country_Code)  + theme(plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30), legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20)) + theme(legend.position="bottom")
p



ggsave("D:\\30daychartchallenge\\30daychart\\day16.png", width=10, height=7, dpi=300)

```

# Day 17- Spotify Top 200 
![Spotify Top 200](https://spotifycharts.com/regional)

```{r Day17} 
# Read in Data for US 
spotify_us <- fread("https://spotifycharts.com/regional/us/daily/latest/download")

# Remove top 2 rows and set column names
spotify_us <- spotify_us[2:202,]
names(spotify_us) <- spotify_us %>% slice(1) %>% unlist()
spotify_us <- spotify_us[2:201,]
spotify_us$Streams <- as.numeric(spotify_us$Streams)

# Read in Data for US 
spotify_uk <- fread("https://spotifycharts.com/regional/gb/daily/latest/download")

# Remove top 2 rows and set column names
spotify_uk <- spotify_uk[2:202,]
names(spotify_uk) <- spotify_uk %>% slice(1) %>% unlist()
spotify_uk <- spotify_uk[2:201,]
spotify_uk$Streams <- as.numeric(spotify_uk$Streams)

# merge together 
spotify_compare <- merge(spotify_uk, spotify_us, by=c("Artist", "Track Name"))
spotify_compare$Position.x <- as.numeric(spotify_compare$Position.x)
spotify_compare$Position.y <- as.numeric(spotify_compare$Position.y)
spotify_compare$diff <- spotify_compare$Position.x- spotify_compare$Position.y
spotify_compare$id <- 1:nrow(spotify_compare)
spotify_compare$full <- paste(spotify_compare$`Artist`,spotify_compare$`Track Name`, sep="-")


spotify_compare <- spotify_compare %>% arrange(spotify_compare, Artist)

# Make the plot
p <- ggplot(spotify_compare, aes(x=full, y=diff, group=Artist, fill=Artist)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity",alpha=0.5) +
  theme_minimal() + 
  labs(title="2017 Per Capita CO2 Emissions by Country") +
  theme(
    legend.position = "none",
    text=element_text(color="white"),
    axis.text = element_text(color="white", angle=90),
    #axis.title = element_blank(),
    panel.grid = element_blank(),
    panel.background=element_rect(fill="black"),
    plot.background = element_rect(fill="black"),
    plot.title=element_text(size=12, hjust=0.2, face='bold', color="white"),
    plot.margin = unit(rep(0,4), "cm"
                       ) 
  ) + labs(title="Difference in Top 200 Spotify Chart Position in UK and US") + scale_fill_viridis_d(begin=0, end=0.9) + geom_text(x=spotify_compare$full[5], y=100, label="Higher in UK Charts", color="white", size=10) + geom_text(x=spotify_compare$full[5], y=-100, label="Higher in US Charts", color="white", size=10) + theme(plot.title=element_text(family="sans", size=30, color="white"), axis.text=element_text(family="sans", size=20, color="white"), legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20, color="white"), axis.title=element_blank())
  
p

ggsave("D:\\30daychartchallenge\\30daychart\\day17.png", width=10, height=7, dpi=300)
```


# Day 18- Connections 
```{r Day 18} 
# Read in the data
broadband <- read_xlsx("D://30daychartchallenge//30daychart//data/Broadband-speeds-2020.xlsx", skip=3, sheet=2)
# remove useless columns 
broadband <- subset(broadband, select=c(`MSOA code`, `MSOA name`, `Nation/Region`, `Average download speed (Mbps)`))
# Set column names
colnames(broadband) <- c("MSOA_Code", "MSOA_Name", "Nation_Region", "Speed")

# Remove welsh data 
broadband <- broadband[broadband$Nation_Region!="Wales" & broadband$Nation_Region!="Scotland" & broadband$Nation_Region!="Northern Ireland",]
# Calculate Regional Averages 
averages <- broadband %>% group_by(Nation_Region) %>% summarise("Speed"=mean(Speed, na.rm=TRUE)) 
val <- mean(averages$Speed)

averages <- averages %>% add_row(Nation_Region="National", "Speed"= mean(averages$Speed))

# Subset data to 2 rows from each region 
broadband <- merge(broadband, averages, by="Nation_Region")
broadband$National_Speed <- val
# name columns 
colnames(broadband) <- c("Nation_Region", "MSOA_Code", "MSOA_Name", "Speed", "Region_Speed", "National_Speed")


# Visualise two from each region 
broadband_sub2 <- broadband %>% group_by(Nation_Region) %>% slice(1:2) %>% ungroup()




ggplot(data=broadband_sub2, aes(x=MSOA_Code, y=Speed,fill=Nation_Region)) + geom_bar(stat="identity", alpha=0.8)  + geom_point(data=broadband_sub2, aes(x=MSOA_Code, y=National_Speed, color="white", fill="white"), shape=23, size=2, fill="white", color="white", alpha=0.6) + geom_point(data=broadband_sub2, aes(x=MSOA_Code, y=Region_Speed, fill="black"), shape=1, fill="black", alpha=0.8) + labs(title = "Average Broadband Speeds (Mbps)\nRegional Average in Black and National Average in White") + ylab("Broadband Speed (Mpbs)") + xlab("MSOA Code") + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="sans", face="italic", size=20), plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30),legend.position="bottom", legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20), axis.title = element_text(family="sans", size=20)) + theme(axis.text.x=element_text(angle=90)) 


ggsave("D:\\30daychartchallenge\\30daychart\\day18.png", width=10, height=7, dpi=300)

```

# Day 19- Global Change 
```{r Day 19} 

eruptions <-fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/eruptions.csv')
# Remove year before 0 
eruptions <- eruptions[eruptions$start_year>=1021 & !is.na(eruptions$vei),]

ggplot(data=eruptions, aes(x=start_year, y=latitude, color=vei)) + geom_point(alpha=0.5) + scale_color_viridis_c(direction=-1, option="A") + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="sans", face="italic", size=20), plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30),legend.position="bottom", legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20), axis.title = element_text(family="sans", size=20)) + xlab("Date") + ylab("Latitude") + labs(title="Volcanic Eruptions in the last 1000 years", caption="Source: Tidytuesday | Inspiration from similar post by @marcreid.")

ggsave("D:\\30daychartchallenge\\30daychart\\day19.png", width=10, height=7, dpi=300)

temperature <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/temperature.csv')

temperature <- temperature[temperature$temp_type=="min" & !is.na(temperature$temperature),]

ggplot(data=temperature, aes(x=date, y=city_name, fill=temperature)) + geom_tile() + scale_fill_viridis_c(option="A", direction=-1) + theme(plot.background=element_rect(fill="white", color="#E5E5E3"),panel.background=element_rect(fill="#E5E5E3", color="#E5E5E3"), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.caption = element_text(family="sans", face="italic", size=20), plot.title=element_text(family="sans", size=30), axis.text=element_text(family="sans", size=30),legend.position="bottom", legend.title=element_text(family="sans", size=20), legend.text = element_text(family="sans", size=20), axis.title = element_text(family="sans", size=20)) + xlab("Date") + ylab("Min Temperature (C)")

ggsave("D:\\30daychartchallenge\\30daychart\\day19.png", width=10, height=7, dpi=300)
```

# Day 20- Upwards 
```{r Day 20}
astronauts <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-14/astronauts.csv')
# Keep one instance of each astronaut 
astronauts <- astronauts %>% group_by(name) %>% summarise("hours"=total_hrs_sum, "sex"=sex, "year"=min(year_of_mission)) %>% ungroup()

# Keep one instance of each astronaut to plot total hours in space 
astronauts <- astronauts[!duplicated(astronauts$name),]

# Visualise 
ggplot(data=astronauts, aes(y=hours, x=year)) + 
  geom_segment(data=astronauts[astronauts$sex=="male",],aes(xend=year, color=sex), yend=0, alpha=0.2) +
  geom_segment(data=astronauts[astronauts$sex=="female",],aes(xend=year, color=sex), yend=0, alpha=0.99) +
  geom_point(color="grey", alpha=ifelse(astronauts$sex=="male", 0.2, 0.99), size=ifelse(astronauts$sex=="male", 1, 2)) +
  scale_color_manual(values=c("yellow", "red"))  + labs(title = "**Mission Time in Space**  
    <span style='color:yellow;'>Female</span> and 
    <span style='color:red;'>Male</span> Astronauts") + theme_minimal() +
  theme(
    plot.title = element_markdown(lineheight = 1, size=20, color="dark grey"), legend.position="none", plot.background=element_rect(fill="black", color="black"), panel.background=element_rect(fill="black", color="black"), legend.background=element_rect(fill="black", color="black"), panel.grid = element_blank(), axis.title = element_text(color="dark grey", size=15)) + coord_flip() + xlab("Year of Earliest Mission") + ylab("Total Hours in Space") 

ggsave("D:\\30daychartchallenge\\30daychart\\day20.png",width=7, height=7,  dpi=300)
```


# Day 21- Downwards
[Our World in Data](https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions)
```{r Day 21, fig.height=7, fig.width=10}
# Read in the data
co2<- fread("https://github.com/owid/co2-data/raw/master/owid-co2-data.csv")

# Join on continent data 
# Add Continent
continent <- fread("D:\\30daychartchallenge\\30daychart\\data\\day6continent.csv")
continent <- continent[,c(1,6)]
continent$country[continent$country=="United Kingdom of Great Britain and Northern Ireland"]<-"United Kingdom"

co2 <- merge(co2, continent, by="country")
co2 <- as.data.frame(co2)

# Visualise CO2 per capita through time for each country- just highlight a few for Europe
p <- ggplot(data=co2[co2$continent=="Europe" & co2$year>=2000,], aes(x=year, y=co2_per_capita, group=country)) + geom_line() + theme(legend.position="none") +
  gghighlight(max(co2_per_capita) >10)  + 
  geom_line(data=co2[co2$country=="United Kingdom" & co2$year>=2000,], aes(x=year, y=co2_per_capita), color="blue") + 
  labs(title = "**CO2 per capita emissions (tonnes/yr) in Europe since 2000**  
    <span style='color:black;'>CO2 per capita in 2000 of >10 </span><br>
    <span style='color:blue;'>United Kingdom</span>", caption="Source: OurWorldinData") + theme_minimal() + 
  theme(plot.title = element_markdown(size=30, lineheight=0.5, color="#3b444b", hjust=0), legend.position="none", plot.background=element_rect(fill="grey", color="black"), panel.background=element_rect(fill="white", color="black"), legend.background=element_rect(fill="white", color="black"), panel.grid = element_blank(), axis.title = element_text(color="black", size=15)) + xlab("Year") + ylab("CO2 Per Capita (tonnes/yr)") 

p

ggsave("D:\\30daychartchallenge\\30daychart\\day21.png",width=5, height=6, dpi=300)
```





